{%- set osd_pairs = [] %}
{%- for host in groups['osd-nodes'] %}
{%- set osd_jour = hostvars[host]['osd_jour'] %}
{%- if 'dev-osd-node' in hostvars[host].group_names %}
{%- set env='Dev' %}
{%- else %}
{%- set env='Prod' %}
{%- endif %}
{%- set disks = hostvars[host]['ansible_local']['osd_disks']|difference([osd_jour]) %}
{%- for disk in disks %}
{%- do osd_pairs.append(disk+"-"+osd_jour+"-"+env) %}
{%- endfor %}
{%- endfor %}
---
endpoints:
  identity:
    namespace: openstack
  object_store:
    namespace: ceph
  ceph_mon:
    namespace: ceph
deployment:
  storage_secrets: true
  ceph: true
  rbd_provisioner: true
  cephfs_provisioner: false
  client_secrets: false
  rgw_keystone_user_and_endpoints: false
bootstrap:
  enabled: true
storageclass:
  cephfs:
    provision_storage_class: false
conf:
  features:
    mds: false
  ceph:
    global:
      fsid: "{{ceph_fs_id}}"
      bluestore_block_db_size: "{{bluestore_block_db_size}}"
      bluestore_block_wal_size: "{{bluestore_block_wal_size}}"
      mon osd full ratio: "{{mon_osd_full_ratio}}"
      mon osd nearfull ratio: "{{mon_osd_nearfull_ratio}}"
  rgw_ks:
    enabled: true
  pool:
    crush:
      tunables: {{tunables}}
    target:
      osd: 12
      pg_per_osd: {{pg_per_osd}}
    spec:
      # RBD pool
      - name: cloud.infra 
        application: rbd
        replication: {{replication}}
        percent_total_data: 30
      # RadosGW pools
      - name: .rgw.root
        application: rgw
        replication: {{replication}}
        percent_total_data: 0.1
      - name: default.rgw.control
        application: rgw
        replication: {{replication}}
        percent_total_data: 0.1
      - name: default.rgw.data.root
        application: rgw
        replication: {{replication}}
        percent_total_data: 0.1
      - name: default.rgw.gc
        application: rgw
        replication: {{replication}}
        percent_total_data: 0.1
      - name: default.rgw.log
        application: rgw
        replication: {{replication}}
        percent_total_data: 0.1
      - name: default.rgw.intent-log
        application: rgw
        replication: {{replication}}
        percent_total_data: 0.1
      - name: default.rgw.meta
        application: rgw
        replication: {{replication}}
        percent_total_data: 0.1
      - name: default.rgw.usage
        application: rgw
        replication: {{replication}}
        percent_total_data: 0.1
      - name: default.rgw.users.keys
        application: rgw
        replication: {{replication}}
        percent_total_data: 0.1
      - name: default.rgw.users.email
        application: rgw
        replication: {{replication}}
        percent_total_data: 0.1
      - name: default.rgw.users.swift
        application: rgw
        replication: {{replication}}
        percent_total_data: 0.1
      - name: default.rgw.users.uid
        application: rgw
        replication: {{replication}}
        percent_total_data: 0.1
      - name: default.rgw.buckets.extra
        application: rgw
        replication: {{replication}}
        percent_total_data: 0.1
      - name: default.rgw.buckets.index
        application: rgw
        replication: {{replication}}
        percent_total_data: 3
      - name: default.rgw.buckets.data
        application: rgw
        replication: {{replication}}
        percent_total_data: 34.8

  storage:
    mon:
      directory: /var/lib/ceph/mon
  overrides:
    ceph_osd:
      labels:
{% for osd in osd_pairs|unique %}
{% set params = osd.split('-') %}
       - label: 
           key: D{{params[0]}}-J{{params[1]}}-{{params[2]}}
           values: 
           - "enabled"
         #exclusive: false
         conf:
           storage:
             osd:
               - data:
                   type: block-bluestore
                   location: /dev/{{params[0]}}
                 journal:
                   type: block-bluestore
                   location: /dev/{{params[1]}}
{% endfor %}
ceph_mgr_enabled_modules:
  - restful
  - status
  - prometheus
  - balancer
# Manager default port conflict with cassandra(TungstenFabric)
ceph_mgr_modules_config:
  dashboard:
    port: 7001
endpoints:
  ceph_mgr:
    port:
      mgr:
        default: 7001
